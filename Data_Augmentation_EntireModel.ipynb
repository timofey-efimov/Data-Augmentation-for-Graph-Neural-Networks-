{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqX4idD3cst8"
      },
      "outputs": [],
      "source": [
        "# Installing the necessary libraries and unzipping the dataset\n",
        "\n",
        "# Link to the dataset original page: https://snap.stanford.edu/data/reddit_threads.html\n",
        "!unzip reddit_threads.zip\n",
        "!pip install spektral\n",
        "!pip install POT\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import ot\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "#general libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os \n",
        "import glob \n",
        "import networkx as nx\n",
        "import pdb\n",
        "import networkx.algorithms.isomorphism as iso\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "#spektral\n",
        "from spektral.data import Graph\n",
        "from spektral.data import Dataset\n",
        "from spektral.data import DisjointLoader\n",
        "from spektral.datasets import TUDataset\n",
        "from spektral.models import GeneralGNN\n",
        "from spektral.data import DisjointLoader\n",
        "from spektral.datasets import QM9\n",
        "from spektral.layers import ECCConv, GlobalSumPool, GeneralConv, GatedGraphConv\n",
        "\n",
        "#tensorflow imports \n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import DisjointLoader\n",
        "from spektral.datasets import OGB\n",
        "from spektral.layers import ECCConv, GlobalSumPool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Graphon functions.\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "import scipy as sp\n",
        "from scipy import io\n",
        "from scipy import linalg\n",
        "from scipy import stats\n",
        "import scipy.interpolate as interpolate\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "from copy import copy\n",
        "import math\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "'''\n",
        "Reference:\n",
        "https://github.com/BenjaminSischka/GraphonPy\n",
        "Sischka, Benjamin and Kauermann, Goran.\n",
        "\"EM-based smooth graphon estimation using MCMC and spline-based approaches.\"\n",
        "Social Networks 68. (2022): 279-295.\n",
        "'''\n",
        "\n",
        "# Step function approximation from function\n",
        "def sbm_from_func(func,size):\n",
        "    if np.isscalar(size):\n",
        "        Ui = Uj = np.linspace(0,1,size)\n",
        "        size0 = size1 = size\n",
        "    else:\n",
        "        Ui = np.linspace(0,1,size[0])\n",
        "        Uj = np.linspace(0,1,size[1])\n",
        "        (size0,size1) = size\n",
        "    try:\n",
        "        if func(np.array([0.3,0.7]),np.array([0.3,0.7])).ndim == 1:\n",
        "            if len(Ui)<len(Uj):\n",
        "                sbm = np.array([func(Ui[i],Uj) for i in range(size0)])\n",
        "            else:\n",
        "                sbm = np.array([func(Ui,Uj[j]) for j in range(size1)])\n",
        "        else:\n",
        "            sbm = func(Ui,Uj)\n",
        "    except ValueError:\n",
        "        print('Not appropriate graphon definition, slow from function to matrix derivation.')\n",
        "        sbm = np.zeros((size0,size1))\n",
        "        for i in range(size0):\n",
        "            for j in range(size1):\n",
        "                sbm[i,j] = func(Ui[i],Uj[j])\n",
        "    return sbm\n",
        "\n",
        "# Function approximation from B-Spline coefficients\n",
        "def func_from_theta(theta,tau,order=1,nKnots=None):\n",
        "    if nKnots is None:\n",
        "        nKnots = int(np.sqrt(len(theta)))\n",
        "\n",
        "    if order==0:\n",
        "        prob_mat = theta.reshape((nKnots,nKnots))\n",
        "        def _grad_func(x_eval,y_eval):\n",
        "            vec_x = np.maximum(np.searchsorted(tau, np.array(x_eval, ndmin=1, copy=False)) -1, 0).astype(int)\n",
        "            vec_y = np.maximum(np.searchsorted(tau, np.array(y_eval, ndmin=1, copy=False)) -1, 0).astype(int)\n",
        "            return prob_mat[vec_x][:,vec_y]\n",
        "    else:\n",
        "        def _grad_func(x_eval,y_eval):\n",
        "            x_eval_order = np.argsort(x_eval)\n",
        "            y_eval_order = np.argsort(y_eval)\n",
        "            func_eval_order=interpolate.bisplev(x= np.array(x_eval, ndmin=1, copy=False)[x_eval_order], y=np.array(y_eval, ndmin=1, copy=False)[y_eval_order], tck=(tau, tau, theta, order, order), dx=0, dy=0)\n",
        "            return eval('func_eval_order' + (('[np.argsort(x_eval_order)]' + ('[:,' if len(y_eval_order) > 1 else '')) if len(x_eval_order) > 1 else ('[' if len(y_eval_order) > 1 else '')) + ('np.argsort(y_eval_order)]' if len(y_eval_order) > 1 else ''))\n",
        "    return _grad_func\n",
        "\n",
        "# Function approximation from step function\n",
        "def func_from_sbm(sbm):\n",
        "    def _step_func_aux(u,v):\n",
        "        if np.isscalar(u):\n",
        "            return(sbm[np.minimum(np.floor(u*sbm.shape[0]).astype(int), sbm.shape[0]-1)][np.minimum(np.floor(v*sbm.shape[1]).astype(int), sbm.shape[1]-1)])\n",
        "        else:\n",
        "            return(sbm[np.minimum(np.floor(u*sbm.shape[0]).astype(int), sbm.shape[0]-1)][:, np.minimum(np.floor(v*sbm.shape[1]).astype(int), sbm.shape[1]-1)])\n",
        "    return _step_func_aux\n",
        "\n",
        "# B-Spline coefficients approximation from function\n",
        "# More accurate: if you create system of equations and solve for theta given nKnots**2 equations\n",
        "def theta_from_func(func,nKnots=10):\n",
        "    U = np.linspace(0,1,nKnots)\n",
        "    try:\n",
        "        if func(np.array([0.3,0.7]),np.array([0.3,0.7])).ndim == 1:\n",
        "            prob_mat = np.array([func(U,U[j]) for j in range(nKnots)])\n",
        "        else:\n",
        "            prob_mat = func(U,U)\n",
        "    except ValueError:\n",
        "        print('Not appropriate graphon definition, slow from function to matrix derivation.')\n",
        "        prob_mat = np.zeros((nKnots,nKnots))\n",
        "        for i in range(nKnots):\n",
        "            for j in range(nKnots):\n",
        "                prob_mat[i,j] = func(U[i],U[j])\n",
        "    theta = prob_mat.reshape(nKnots**2)\n",
        "    return theta\n",
        "\n",
        "# Ways to represent graphon: b-spline theta, function, or matrix (needs size)\n",
        "class Graphon:\n",
        "    def __init__(self, func=None, sbm=None, theta=None, nKnots=10, order=1, size=501):\n",
        "        if func is None and sbm is None and theta is None:\n",
        "            print('Error. No information about graphon.')\n",
        "\n",
        "        if theta is not None:\n",
        "            nKnots = int(np.sqrt(len(theta)))\n",
        "        self.nKnots = nKnots\n",
        "        self.tau = np.concatenate(([0],np.linspace(0,1,self.nKnots),[1]))\n",
        "        self.order = order\n",
        "\n",
        "        if func is not None:\n",
        "            self.func = func\n",
        "            self.sbm = sbm_from_func(func,size=size)\n",
        "            self.theta = theta_from_func(func,nKnots=nKnots)\n",
        "        elif sbm is not None:\n",
        "            self.sbm = sbm\n",
        "            self.func = func_from_sbm(sbm)\n",
        "            self.theta = theta_from_func(self.func,nKnots=nKnots)\n",
        "        else:\n",
        "            self.theta = theta\n",
        "            self.func = func_from_theta(theta,tau=self.tau,order=order,nKnots=nKnots)\n",
        "            self.sbm = sbm_from_func(self.func,size)\n",
        "    def sample_graph(self,N,z=None,sorted=False):\n",
        "        if z is None:\n",
        "            z = np.random.random(N)\n",
        "        elif len(z)!=N:\n",
        "            N = len(z)\n",
        "        if sorted:\n",
        "            z = np.sort(z)\n",
        "        try:\n",
        "            if self.func(np.array([0.3,0.7]),np.array([0.3,0.7])).ndim == 1:\n",
        "                A = np.array([np.random.binomial(1,self.func(z,z[i])) for i in range(N)])\n",
        "            else:\n",
        "                A = np.random.binomial(1,self.func(z,z))\n",
        "        except ValueError:\n",
        "            A = np.zeros((N,N),dtype=int)\n",
        "            for i in range(N):\n",
        "                for j in range(N):\n",
        "                    A[i,j] = np.random.binomial(1,self.func(z[i],z[j]))\n",
        "        A[np.tril_indices(N)] = A.T[np.tril_indices(N)]\n",
        "        A[np.eye(N)==1] = 0\n",
        "        return A,z\n",
        "\n",
        "def graphon_from_example(idx, size=101,nKnots=10):\n",
        "    examples = {\n",
        "                0: lambda u,v: 1/2*(u**2+v**2),\n",
        "                1: lambda u,v: 1/2*(u+v),\n",
        "                2: lambda u,v: ((1-u)*(1-v))**(1/1) * 0.8 + (u*v)**(1/1) * 0.85,\n",
        "                3: lambda u,v: np.exp(-5*np.abs(u-v))\n",
        "                }\n",
        "    return Graphon(func=examples[idx],size=size,nKnots=nKnots)\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "'''\n",
        "Reference:\n",
        "Chan, Stanley and Airoldi, Edoardo.\n",
        "\"A Consistent Histogram Estimator for Exchangeable Graph Models.\"\n",
        "ICML, PMLR 32(1) (2014): 208-216.\n",
        "'''\n",
        "def graphon_from_sas(A,z=None,num_bins=5,nKnots=10):\n",
        "    (N,N) = A.shape\n",
        "    if z is None:\n",
        "        deg = np.sum(A,axis=0)\n",
        "        ord_deg = np.argsort(deg)\n",
        "        A = A[ord_deg,:][:,ord_deg]\n",
        "        z = (deg[ord_deg]/max(deg+1))\n",
        "\n",
        "    num_bins = int(np.minimum(N,num_bins))\n",
        "    F = np.kron(np.eye(num_bins),np.ones((int(np.ceil(N/num_bins)),int(np.ceil(N/num_bins))))-np.eye(int(np.ceil(N/num_bins))))[:N,:N]\n",
        "    F[np.sum(F,axis=0)>0,:]/=(np.sum(F,axis=0)[np.sum(F,axis=0)>0]).reshape(-1,1)\n",
        "\n",
        "    sbm = F@A@F.T\n",
        "    W_est = Graphon(sbm=sbm,nKnots=nKnots)\n",
        "    return W_est\n",
        "\n",
        "\n",
        "def GWDistance(A1, A2):\n",
        "  C1 = sp.spatial.distance.cdist(A1, A1)\n",
        "  C2 = sp.spatial.distance.cdist(A2, A2)\n",
        "\n",
        "  C1 /= C1.max()\n",
        "  C2 /= C2.max()\n",
        "  p = ot.unif(len(A1))\n",
        "  q = ot.unif(len(A2))\n",
        "\n",
        "  gw0, log0 = ot.gromov.gromov_wasserstein(\n",
        "      C1, C2, p, q, 'square_loss', verbose=True, log=True)\n",
        "\n",
        "\n",
        "  return log0['gw_dist']"
      ],
      "metadata": {
        "id": "A3VLxzVjdUKc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_graph(lst):\n",
        "  \"\"\"\n",
        "  Currently data is represented as dictionary, where\n",
        "  string with graph ID is mapped to list of all edges.\n",
        "  This function takes list of edges for the given graphs\n",
        "  and outputs adjacency matrix \n",
        "  \"\"\"\n",
        "  lst = np.array(lst)\n",
        "  size = np.max(np.reshape(np.array(lst), 2*len(lst)))+1\n",
        "\n",
        "  # Initialize adjacency matrix\n",
        "  A = np.zeros((size, size))\n",
        "  for elem in lst:\n",
        "    a, b = elem[0], elem[1]\n",
        "    A[a][b] = 1\n",
        "    A[b][a] = 1\n",
        "  return A"
      ],
      "metadata": {
        "id": "m1B7m0wldi_V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset from .csv file\n",
        "\n",
        "rt = pd.read_csv('reddit_threads/reddit_target.csv') \n",
        "with open('/content/reddit_threads/reddit_edges.json') as f:\n",
        "  data = json.load(f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "pO1mx-j9djBx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spektral.data import Graph\n",
        "from spektral.transforms.normalize_adj import NormalizeAdj\n",
        "from numpy import linalg as LA\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset for training GNN for binary classification, \n",
        "    before augmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, id, target,indices, **kwargs):\n",
        "        \"\"\"\n",
        "          Inputs:\n",
        "            - data, the graphs themselves\n",
        "            - id, the ID number assigned to the graph to keep track of it \n",
        "            - target, true labels of the graph\n",
        "            - indices, which graphs from the entire dataset use for the model\n",
        "          Outputs:\n",
        "            - \n",
        "            -\n",
        "            - \n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.id = id\n",
        "        self.target = target\n",
        "        # Number of graphs in the dataset\n",
        "        self.number = indices[1]-indices[0]\n",
        "        self.indices = indices\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def read(self):\n",
        "        # Create one graph, which is i-th in the dataset\n",
        "        def make_graph(i):\n",
        "            # Convert to string to access in the original dataset format \n",
        "            i = str(i)\n",
        "\n",
        "            # Get its adjacency matrix \n",
        "            A = convert_graph(self.data[i])\n",
        "\n",
        "            # Return graphs with features, its adjacency matrix, and target label\n",
        "            return Graph(x=features(A).astype(float), a=csr_matrix(A), y=[target[int(i)]])\n",
        "\n",
        "        # We must return a list of Graph objects\n",
        "\n",
        "        return [make_graph(_) for _ in range(self.indices[0], self.indices[1])]\n",
        "\n",
        "def features(A):\n",
        "  \"\"\"\n",
        "  Extracting features for the graph, \n",
        "  given adjacency matrix A.\n",
        "\n",
        "  Features are:\n",
        "\n",
        "  In and out degree. Classification\n",
        "  is entirely topology-based. \n",
        "\n",
        "  \"\"\"\n",
        "  degreesIn = np.sum(A,axis=1)\n",
        "  degreesOut = np.sum(A,axis=0)\n",
        "  return np.column_stack((degreesIn, degreesOut))\n"
      ],
      "metadata": {
        "id": "nJpmds0KdjET"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id = rt['id']\n",
        "target = rt['target']\n",
        "\n",
        "# Create datasets for training, validation, and testing\n",
        "data_train = MyDataset(data = data, id = id, target = target, indices = [0,500], transforms=NormalizeAdj())\n",
        "\n",
        "data_val = MyDataset(data = data, id = id, target = target, indices = [10000,10200],transforms=NormalizeAdj())\n",
        "\n",
        "data_test = MyDataset(data = data, id = id, target = target, indices = [10200,11900],transforms=NormalizeAdj())"
      ],
      "metadata": {
        "id": "BFqN05oUd-Z0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Networks itself\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import Dataset, DisjointLoader, Graph\n",
        "from spektral.layers import GCSConv, GlobalAvgPool\n",
        "from spektral.transforms.normalize_adj import NormalizeAdj\n",
        "\n",
        "val_loss_array = []\n",
        "training_loss = []\n",
        "\n",
        "################################################################################\n",
        "# Config\n",
        "################################################################################\n",
        "learning_rate = 1e-3  # Learning rate\n",
        "epochs = 40  # Number of training epochs\n",
        "batch_size =  8 # Batch size\n",
        "\n",
        "\n",
        "data_tr = data_train\n",
        "data_va = data_val\n",
        "data_te = data_test\n",
        "\n",
        "\n",
        "# Data loaders\n",
        "loader_tr = DisjointLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
        "loader_va = DisjointLoader(data_va, batch_size=batch_size,epochs=5)\n",
        "loader_te = DisjointLoader(data_te, batch_size=batch_size,epochs=15)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Build model\n",
        "################################################################################\n",
        "class Net(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCSConv(5, activation=\"relu\")\n",
        "        self.conv2 = GCSConv(7, activation=\"relu\")\n",
        "        self.conv3 = GCSConv(5, activation=\"relu\")\n",
        "        self.global_pool = GlobalAvgPool()\n",
        "        self.dense = Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, a, i = inputs\n",
        "        x = self.conv1([x, a])\n",
        "        x = self.conv2([x, a])\n",
        "        x = self.conv3([x, a])\n",
        "        output = self.global_pool([x, i])\n",
        "        output = self.dense(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "model = Net()\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "\n",
        "# Loss for training\n",
        "loss_fn1 = MeanSquaredError()\n",
        "\n",
        "#Loss for evaluation\n",
        "loss_fn2 = MeanSquaredError()\n",
        "\n",
        "################################################################################\n",
        "# Fit model\n",
        "################################################################################\n",
        "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "def train_step(inputs, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        print(\"Target: {}\".format(target))\n",
        "        predictions = model(inputs, training=True)\n",
        "        print(\"Predictions: {}\".format(predictions))\n",
        "        loss = loss_fn1(target, predictions) + sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "step = loss = 0\n",
        "for batch in loader_tr:\n",
        "    step += 1\n",
        "    loss += train_step(*batch)\n",
        "    \n",
        "    if step == loader_tr.steps_per_epoch:\n",
        "        step = 0\n",
        "        print(\"Loss: {}\".format(loss / loader_tr.steps_per_epoch))\n",
        "        training_loss.append(format(loss / loader_tr.steps_per_epoch))\n",
        "        loss = 0\n",
        "\n",
        "################################################################################\n",
        "# Evaluate model\n",
        "################################################################################\n",
        "print(\"Testing model\")\n",
        "loss = 0\n",
        "for batch in loader_te:\n",
        "    inputs, target = batch\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss += loss_fn2(target, predictions)\n",
        "loss /= 15*loader_te.steps_per_epoch\n",
        "print(\"Done. Test loss: {}\".format(loss))"
      ],
      "metadata": {
        "id": "D641JHD8MsyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a52a60-0e56-4c0a-f45b-265da45b13b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.8/dist-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
            "  np.random.shuffle(a)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: Tensor(\"target:0\", shape=(None, 1), dtype=int64)\n",
            "Predictions: Tensor(\"net/dense/Sigmoid:0\", shape=(None, 1), dtype=float32)\n",
            "Target: Tensor(\"target:0\", shape=(None, 1), dtype=int64)\n",
            "Predictions: Tensor(\"net/dense/Sigmoid:0\", shape=(None, 1), dtype=float32)\n",
            "Loss: 0.23697522282600403\n",
            "Loss: 0.22588703036308289\n",
            "Loss: 0.21799401938915253\n",
            "Loss: 0.21146881580352783\n",
            "Loss: 0.20579840242862701\n",
            "Loss: 0.20222748816013336\n",
            "Loss: 0.19836167991161346\n",
            "Loss: 0.19726741313934326\n",
            "Loss: 0.19421568512916565\n",
            "Loss: 0.19432583451271057\n",
            "Loss: 0.19232378900051117\n",
            "Loss: 0.19312359392642975\n",
            "Loss: 0.19199298322200775\n",
            "Loss: 0.19159278273582458\n",
            "Loss: 0.1922541707754135\n",
            "Loss: 0.19012519717216492\n",
            "Loss: 0.18940487504005432\n",
            "Loss: 0.1908678561449051\n",
            "Loss: 0.18827761709690094\n",
            "Loss: 0.18745368719100952\n",
            "Loss: 0.18786120414733887\n",
            "Loss: 0.1861790269613266\n",
            "Loss: 0.1878013163805008\n",
            "Loss: 0.18506069481372833\n",
            "Loss: 0.18756449222564697\n",
            "Loss: 0.18579590320587158\n",
            "Loss: 0.18639785051345825\n",
            "Loss: 0.1848546862602234\n",
            "Loss: 0.18429683148860931\n",
            "Loss: 0.18570300936698914\n",
            "Loss: 0.18564373254776\n",
            "Loss: 0.18236269056797028\n",
            "Loss: 0.18409068882465363\n",
            "Loss: 0.18291592597961426\n",
            "Loss: 0.1819065511226654\n",
            "Loss: 0.18185989558696747\n",
            "Loss: 0.18132299184799194\n",
            "Loss: 0.18166950345039368\n",
            "Loss: 0.1800612509250641\n",
            "Loss: 0.18205542862415314\n",
            "Testing model\n",
            "Done. Test loss: 0.1938006430864334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training loss \n",
        "\n",
        "tr_ls = []\n",
        "for elem in training_loss:\n",
        "  tr_ls.append(float(elem))\n",
        "\n",
        "plt.plot(tr_ls)\n",
        "\n",
        "plt.title('Training loss, original dataset')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Training loss, MSE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "4bZqMGsUM--5",
        "outputId": "032bb854-2c7f-4486-9896-01cbfa965741"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training loss, MSE')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_graphons(listA):\n",
        "  \"\"\"\n",
        "  Function to make a linear combination\n",
        "  of multiple graphons\n",
        "\n",
        "  Inputs:\n",
        "    -listA, a list of adjacency matrices for \n",
        "    the graphs. For this group\n",
        "    we want to create one graphon. \n",
        "  \"\"\"\n",
        "\n",
        "  # Create space to store graphon's SBM\n",
        "  # represented as matrix\n",
        "  min_length = np.shape(listA[0])[1]\n",
        "  graphon = np.zeros((min_length, min_length))\n",
        "  \n",
        "  for elem in listA:\n",
        "    # Graphon inference from individual adjacency\n",
        "    SWgraphon = graphon_from_sas(elem,num_bins=(int(min_length/2)+1))\n",
        "    graphon = graphon+SWgraphon.sbm\n",
        "  \n",
        "  # Normalize graphon values \n",
        "  graphon = graphon / len(listA)\n",
        "\n",
        "  # Return graphon's SBM as matrix\n",
        "  return graphon\n",
        "\n",
        "def augment(dims, target, training_dataset):\n",
        "  \"\"\"\n",
        "\n",
        "  Function that augments the dataset.\n",
        "  Inputs:\n",
        "    -dims, list of dimensions for all graphs\n",
        "    in the dataset we want to augment\n",
        "    -target, target labels of graphs we want to\n",
        "    perform augmentation on\n",
        "    -training_dataset, for which set of graphs augment the data,\n",
        "    their adjacency matrices\n",
        "  Outputs:\n",
        "    - list of lists. Individual element\n",
        "    is tuple with the new adjacency matrix \n",
        "    and its labels \n",
        "\n",
        "  \"\"\"\n",
        "  dims = np.array(dims)\n",
        "\n",
        "  all_results={}\n",
        "  for _ in dims:\n",
        "    # a = np.where(dims == _)\n",
        "    for l in [0,1]:\n",
        "      # Get all graphs that have this dimension _\n",
        "      all_graphs_one_dim = np.where(dims == _)\n",
        "      all_graphs_one_dim = list(all_graphs_one_dim[0])\n",
        "\n",
        "      # Get all graphs with label l\n",
        "      all_graphs_one_label = np.where(target == l)\n",
        "      all_graphs_one_label = list(all_graphs_one_label[0])\n",
        "\n",
        "      # Get graphs same dimension, same label\n",
        "      one_dim_one_label = np.intersect1d(np.array(all_graphs_one_dim), np.array(all_graphs_one_label))\n",
        "      results_augmentation_one = np.zeros((len(one_dim_one_label), _,_))\n",
        "      iter = 0\n",
        "      for elem in one_dim_one_label:\n",
        "        results_augmentation_one[iter] = training_dataset[elem]\n",
        "        iter += 1\n",
        "      if len(one_dim_one_label) > 0:\n",
        "        result_of_graphon_comb = combine_graphons(results_augmentation_one)\n",
        "        all_results[(_,l)] = result_of_graphon_comb\n",
        "  return all_results "
      ],
      "metadata": {
        "id": "4NpL76nddjHL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For which set of graphs augment the data\n",
        "training_dataset = []\n",
        "\n",
        "# Store dimensions of all graphs\n",
        "dims = []\n",
        "\n",
        "starting_graph_index = 0\n",
        "ending_graph_index = 500\n",
        "\n",
        "for i in range(starting_graph_index, ending_graph_index):\n",
        "  training_dataset.append(convert_graph(data[str(i)]))\n",
        "  dims.append(len(convert_graph(data[str(i)])))\n",
        "\n",
        "dims = np.array(dims)"
      ],
      "metadata": {
        "id": "SpRaGB-MdjJu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get targets for the dataset\n",
        "target = rt['target']\n",
        "\n",
        "# Get graphons and labels for result of augmentation\n",
        "result_of_augmentation = augment(dims, np.array(target[starting_graph_index:ending_graph_index]), training_dataset)\n",
        "\n",
        "for elem in result_of_augmentation.keys():\n",
        "  Adj = result_of_augmentation[elem]"
      ],
      "metadata": {
        "id": "yYfXBoGvdjMH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmented Dataset creation(only augmented data) \n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset with the newly generated graphs\n",
        "    for augmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, **kwargs):\n",
        "        # Data is list of graphons and labels\n",
        "        self.data = data\n",
        "        # to store all Gromow-Wasserstein distances, used for plotting\n",
        "        self.GWdist = []\n",
        "        # to store all minimal Gromow-Wasserstein distances for one graphon, used for plotting\n",
        "        self.minGW = []\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def read(self):\n",
        "        def make_graph(elem):\n",
        "          \n",
        "          # Get SBM for graphon, and lavbel \n",
        "          _, label = elem[0], elem[1]\n",
        "          # Adj is actually graphon's SBM\n",
        "          Adj = self.data[elem]\n",
        "          # create graphon\n",
        "          smpl_gr = Graphon(sbm = Adj)\n",
        "\n",
        "          # size for the new graph\n",
        "          N = 3*len(Adj)\n",
        "\n",
        "          # binomial distribution to sample\n",
        "          zeta = np.sort(np.random.random(N))\n",
        "\n",
        "          # store all GW distances\n",
        "          tempGW = []\n",
        "\n",
        "          # store all minimal GW distances \n",
        "          tempM = []\n",
        "\n",
        "          # among how many sa,pled graphs to choose the best \n",
        "          num_graphs_per_graphon = 1\n",
        "\n",
        "          for i in range(num_graphs_per_graphon):\n",
        "            # sample graph from graphon\n",
        "            sample,_ =  smpl_gr.sample_graph(N,z=zeta)\n",
        "            # create graph from matrix\n",
        "            G_sample = nx.from_numpy_matrix(sample)\n",
        "\n",
        "            # get only connected component \n",
        "            for component in list(nx.connected_components(G_sample)):\n",
        "                if len(component)<3:\n",
        "                    for node in component:\n",
        "                        G_sample.remove_node(node)\n",
        "            if G_sample.number_of_edges() > 0:\n",
        "              new_Adj = nx.to_numpy_array(G_sample)\n",
        "              tempM.append(new_Adj)\n",
        "              tempGW.append(float(GWDistance(new_Adj, Adj)))\n",
        "              self.GWdist.append(float(GWDistance(new_Adj, Adj)))\n",
        "          # return the closest one\n",
        "          if len(tempGW)>0:\n",
        "            self.minGW.append(min(tempGW))\n",
        "            new_Adj = tempM[0]\n",
        "            return Graph(x=features(new_Adj).astype(float), a=csr_matrix(new_Adj), y=[label])\n",
        "\n",
        "        return [make_graph(_) for _ in self.data.keys()]"
      ],
      "metadata": {
        "id": "g-3VhFa8djOl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = MyDataset(data=result_of_augmentation, transforms=NormalizeAdj())"
      ],
      "metadata": {
        "id": "tiB6-4mUdUM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmented Dataset and Graph Neural Network\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import Dataset, DisjointLoader, Graph\n",
        "from spektral.layers import GCSConv, GlobalAvgPool\n",
        "from spektral.transforms.normalize_adj import NormalizeAdj\n",
        "\n",
        "val_loss_array = []\n",
        "training_loss = []\n",
        "\n",
        "################################################################################\n",
        "# Config\n",
        "################################################################################\n",
        "learning_rate = 1e-3  # Learning rate\n",
        "epochs = 40  # Number of training epochs\n",
        "batch_size = 8 # Batch size\n",
        "\n",
        "\n",
        "data_tr = data_train+data_aug\n",
        "print(data_tr)\n",
        "data_va = data_val\n",
        "data_te = data_test\n",
        "\n",
        "\n",
        "# Data loaders\n",
        "loader_tr = DisjointLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
        "loader_va = DisjointLoader(data_va, batch_size=batch_size,epochs=5)\n",
        "loader_te = DisjointLoader(data_te, batch_size=batch_size,epochs=15)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Build model\n",
        "################################################################################\n",
        "class Net(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCSConv(5, activation=\"relu\")\n",
        "        self.conv2 = GCSConv(7, activation=\"relu\")\n",
        "        self.conv3 = GCSConv(5, activation=\"relu\")\n",
        "        self.global_pool = GlobalAvgPool()\n",
        "        self.dense = Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, a, i = inputs\n",
        "        x = self.conv1([x, a])\n",
        "        x = self.conv2([x, a])\n",
        "        x = self.conv3([x, a])\n",
        "        output = self.global_pool([x, i])\n",
        "        output = self.dense(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "model = Net()\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "loss_fn1 = MeanSquaredError()\n",
        "loss_fn2 = MeanSquaredError()\n",
        "\n",
        "################################################################################\n",
        "# Fit model\n",
        "################################################################################\n",
        "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "def train_step(inputs, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        print(\"Target: {}\".format(target))\n",
        "        predictions = model(inputs, training=True)\n",
        "        print(\"Predictions: {}\".format(predictions))\n",
        "        loss = loss_fn1(target, predictions) + sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "step = loss = 0\n",
        "for batch in loader_tr:\n",
        "    step += 1\n",
        "    loss += train_step(*batch)\n",
        "    \n",
        "    if step == loader_tr.steps_per_epoch:\n",
        "        step = 0\n",
        "        print(\"Loss: {}\".format(loss / loader_tr.steps_per_epoch))\n",
        "        training_loss.append(format(loss / loader_tr.steps_per_epoch))\n",
        "        loss = 0\n",
        "\n",
        "################################################################################\n",
        "# Evaluate model\n",
        "################################################################################\n",
        "print(\"Testing model\")\n",
        "loss = 0\n",
        "for batch in loader_te:\n",
        "    inputs, target = batch\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss += loss_fn2(target, predictions)\n",
        "loss /= 15*loader_te.steps_per_epoch\n",
        "print(\"Done. Test loss: {}\".format(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTakQXkQJgdC",
        "outputId": "4874116a-00d5-4999-c5fc-dd4c8f7f1927"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Test loss: 0.1875121295452118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training loss \n",
        "\n",
        "tr_ls = []\n",
        "for elem in training_loss:\n",
        "  tr_ls.append(float(elem))\n",
        "\n",
        "plt.plot(tr_ls)\n",
        "\n",
        "plt.title('Training loss, augmented dataset')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Training loss, MSE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Q6IeHt5kJggf",
        "outputId": "2d412111-a450-47eb-9a67-7ca6b7c304e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training loss, MSE')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yV9f3//8cziySsEKYkTEFZMjTgwj0qDrBaFevWVq11tNpfv1pra60dSm3Vuq2V1vbjwGrFiQsRB7L3JiIQQMLeIeP1++O6Yg8x4yTk5GS87rfbuZ1z7dd1Bc7rXO/3+3q/ZWY455xzZSXEOwDnnHP1kycI55xz5fIE4ZxzrlyeIJxzzpXLE4RzzrlyeYJwzjlXLk8QrlKS3pZ0RW2vW80YTpS0prb366In6UpJn1Rj/ZWSTo1lTC72PEE0QpJ2RrxKJO2JmL6kOvsysxFm9o/aXtfVLUkfSfpBvOMojyST1KuxHKcxSYp3AK72mVmL0s+SVgI/MLP3y64nKcnMiuoyNudcw+F3EE1IaVGNpP8naT3wrKQ2kt6QlC9pS/g5O2Kbb355lhYzSPpTuO6XkkbUcN0ekj6WtEPS+5IelfSvKM+jb3isrZIWSBoZsexMSQvD/eZJ+lk4v114blslbZY0WVKV//6juD77FaVIujvyPCRdLukrSZsk3RW5frjuOEn/CuOdJ+kQSXdI2iBptaTTI/bVWtIzktaF53avpMSqrrek3wHHAY+Ed5GPhPP7SHovvB5LJF0Ycay2ksZL2i5pKnBwFdfpsojzvLPMsmGSPg+v/TpJj0hKCZd9HK42J4ztoiiu+ZWScsNr9qUi7oolXS1pUbjdBEndKjpOZefjAp4gmp5OQCbQDbiW4N/As+F0V2AP8Egl2x8JLAHaAfcDz0hSDdb9P2Aq0Ba4G7gsmuAlJQOvA+8CHYCbgH9LOjRc5RngOjNrCQwAPgzn3wasAdoDHYFfANH0M1Pd6xMZaz/gMeAS4CCgNZBVZrVzgOeANsAsYEJ4zCzgHuDJiHXHAkVAL2AIcDoQWWxU7vU2szuBycCNZtbCzG6U1Bx4j+Dv0AEYDTwWxgzwKLA3jPvq8FXZeT5O8DfsTPA3zY5YpRj4aRjX0cApwA0AZnZ8uM6gMLYXqeSah3E/DIwI/8bHALPDZaMI/q7nEfydJwPPV3IcVxUz81cjfgErgVPDzycC+4DUStYfDGyJmP6IoIgK4EpgecSydIIv2U7VWZfgP30RkB6x/F/AvyqI6URgTfj5OGA9kBCx/Hng7vDzKuA6oFWZfdwDvAb0OsDrWfb6fHN9w+m7S88D+BXwfJlrsC/i73E38F7E8nOAnUBiON0yvGYZBEmtAEiLWP9iYGJ1/zbh9EXA5DLn9iTwayARKAT6RCz7PfBJBdfkV8ALEdPNI8+znPV/ArwaMW2V/V0ir3m4763A+ZHXIlz2NnBNxHQCsBvoFs1x/PXtl99BND35Zra3dEJSuqQnw+KB7cDHQEZp0UU51pd+MLPd4ccW1Vy3M7A5Yh7A6ijj7wysNrOSiHlf8b9f5ucDZwJfSZok6ehw/hhgOfBuWDxxezQHq8H1+VaspRPh+W4qs87XEZ/3ABvNrDhiGoJr1g1IBtaFRTVbCb7QO0RsX52/TTfgyNJ9hfu7hCCBtyeon4z8m3xVjfPcFXmeYbHZG5LWh9fw9wR3E+Wq7JqH+74IuD68Fm9K6hNxTg9FnM9mQHz7rs1FyRNE01O2WOU24FDgSDNrBZTeildUbFQb1gGZktIj5nWJctu1QBftX3/QFcgDMLNpZjaK4Ivzv8BL4fwdZnabmfUERgK3SjoliuNVdX12EfxaL9Up4vM6IopaJKURFL/UxGqCO4h2ZpYRvlqZWf8oty/7d18NTIrYV4YFRS8/AvIJ7vAi/yZdK9n3ush1w79r5Hk+DiwGeofX8BdU/u+r0mtuZhPM7DSC4q/FwNMR53RdmXNKM7PPKjmWq4QnCNeS4JfqVkmZBEUMMWVmXwHTgbslpYS/8s+JcvMvCIoNfi4pWdKJ4bYvhPu6RFJrMysEtgMlAJLOltQrrAPZRlAuXrpsrKSxFRyvquszGxgdxpIDfC9i2cvAOZKOCStl76aGidfM1hHUuzwgqZWkBEkHSzohyl18DfSMmH4DOCSsXE4OX0Ml9Q3vYF4h+Pukh3UMlT3f8jJwtqTh4Xnew/7fLS0J/hY7w1/7P6oitgqvuaSOkkaFdREFBEVypXeTTwB3SOofrtta0gWVHMdVwROEexBIAzYCU4B36ui4lxBUWG4C7gVeJPgPXykz20eQEEYQxPwYcLmZLQ5XuQxYGRZNXB8eB6A38D7BF8rnwGNmNjFc1gX4tIJDVnV97iJo4bMF+A1BpW9prAsIKtFfIPiVvRPYEM15VuByIAVYGB7vZYJf0dF4CPhe2LrnYTPbQVDJPZrgrmw9cB/QLFz/RoLiqfUElePPVrTj8Dx/THDu68LYIh9s/BnwfWAHwa/9shXEdwP/CIuGLqTya54A3BrGvBk4gTDhmNmr4Tm8EP795xP8O6noOK4KCitvnIsrSS8Ci80s5ncwZY6bAswBBoZ3HbE8VguCCtbeZvZlLI/lXG3wOwgXF2FxxsFhUckZwCiCOoM6ZWb7zKxvrJKDpHPCYprmwJ+AeQQtn5yr9zxBuHjpRND0cidBu/YfmdmsuEYUG6MIikPWEhRzjTa/bXcNhBcxOeecK5ffQTjnnCtXo+msr127dta9e/d4h+Gccw3KjBkzNppZ+/KWNZoE0b17d6ZPnx7vMJxzrkGRVOFT8l7E5JxzrlyeIJxzzpXLE4RzzrlyeYJwzjlXLk8QzjnnyuUJwjnnXLk8QTjnnCtXk08Q2/YU8uD7S5mzemu8Q3HOuXqlyScIgAffX8YXX5YdCdI555q2Jp8gWqcl0zI1ibwte6pe2TnnmpAmnyAAsjLSWOMJwjnn9uMJAshuk07eVk8QzjkXyRMEkN0mjbwte/CxMZxz7n88QRAUMe0oKGL7nqJ4h+Kcc/WGJwiCOwiANVt3xzkS55yrPzxBAFmlCcIrqp1z7hueIAiKmABv6uqccxE8QQCZzVNIS070lkzOORfBEwQgiaw2aazZ4nUQzjlXyhNEKCsjze8gnHMugieIUOmzEM455wIxTRCSzpC0RNJySbeXs/xWSQslzZX0gaRuEcuKJc0OX+NjGScELZm27C5kV4E/C+GccxDDBCEpEXgUGAH0Ay6W1K/MarOAHDMbCLwM3B+xbI+ZDQ5fI2MVZ6lvWjJ5MZNzzgGxvYMYBiw3s1wz2we8AIyKXMHMJppZac3wFCA7hvFUKrtNOuBNXZ1zrlQsE0QWsDpiek04ryLXAG9HTKdKmi5piqRzy9tA0rXhOtPz8/MPKNhvnqb2lkzOOQdAUrwDAJB0KZADnBAxu5uZ5UnqCXwoaZ6ZrYjczsyeAp4CyMnJOaCe9tq3aEZKYgJrvIjJOeeA2N5B5AFdIqazw3n7kXQqcCcw0swKSuebWV74ngt8BAyJYawkJIjOGalexOScc6FYJohpQG9JPSSlAKOB/VojSRoCPEmQHDZEzG8jqVn4uR1wLLAwhrEChA/LeYJwzjmIYYIwsyLgRmACsAh4ycwWSLpHUmmrpDFAC2BcmeasfYHpkuYAE4E/mlnsE4Q/LOecc9+IaR2Emb0FvFVm3q8iPp9awXafAYfFMrbyZLdJJ39HAXsLi0lNTqzrwzvnXL3iT1JHKH0WYq3fRTjnnCeISKXjQngxk3POeYLYT+mzEN6SyTnnPEHsp1OrVBIT5C2ZnHMOTxD7SUpMoFOrVC9ics45PEF8S5Z3++2cc4AniG/JzvCR5ZxzDjxBfEtWmzTWb99LYXFJvENxzrm48gRRRnabNEoM1m/bG+9QnHMurjxBlJGVEYwL4S2ZnHNNnSeIMvxhOeecC3iCKKNzRirgAwc555wniDKaJSXSoWUzb+rqnGvyPEGUI6uNd/vtnHOeIMqR3SbdK6mdc02eJ4hyZGWksW7bHkpKDmiYa+eca9A8QZQjq00ahcXGhh0FVa/snHONVEwThKQzJC2RtFzS7eUsv1XSQklzJX0gqVuZ5a0krZH0SCzjLKu0229vyeSca8piliAkJQKPAiOAfsDFkvqVWW0WkGNmA4GXgfvLLP8t8HGsYqxIdoY/C+Gcc7G8gxgGLDezXDPbB7wAjIpcwcwmmlnpz/QpQHbpMklHAB2Bd2MYY7myvrmD8AThnGu6YpkgsoDVEdNrwnkVuQZ4G0BSAvAA8LPKDiDpWknTJU3Pz88/wHD/Jz0liczmKZ4gnHNNWr2opJZ0KZADjAln3QC8ZWZrKtvOzJ4ysxwzy2nfvn2txpSV4c9COOeatqQY7jsP6BIxnR3O24+kU4E7gRPMrLTZ0NHAcZJuAFoAKZJ2mtm3KrpjJSsjjWUbdtTV4Zxzrt6JZYKYBvSW1IMgMYwGvh+5gqQhwJPAGWa2oXS+mV0Ssc6VBBXZdZYcIGjJ9NHSDZgZkury0M45Vy/ErIjJzIqAG4EJwCLgJTNbIOkeSSPD1cYQ3CGMkzRb0vhYxVNdWW3S2FtYwqZd++IdinPOxUUs7yAws7eAt8rM+1XE51Oj2MdYYGxtx1aVrNKmrlv20K5Fs7o+vHPOxV29qKSuj7Lb+MBBzrmmzRNEBf43cJA/Te2ca5o8QVSgdVoyLZsl+bgQzrkmyxNEJbLapHkRk3OuyfIEUYlsHzjIOdeEeYKoRFZGGnlb9mDm40I455oeTxCVyG6Tzo6CIrbvKYp3KM45V+c8QVTim15dvSWTc64J8gRRiciH5ZxzrqmpMEFIeini831lltX5GA3xkO3jQjjnmrDK7iB6R3w+rcyy2u1bu57KbJ5CanKCt2RyzjVJlSWIypruNIlmPZK+acnknHNNTWWd9aWH3XEnAGnhZ4WvtLoIrj7IbpPuldTOuSapsgSxHvhzOZ9Lp5uErDZpzF2zNd5hOOdcnaswQZjZiXUYR72VlZHGlt2F7CooonmzmPaO7pxz9UplrZiGSuoUMX25pNckPSwps27Ci7/SlkxfbfJiJudc01JZJfWTwD4ASccDfwT+CWwDnop9aPVDTvdMUhITeHpybrxDcc65OlVZgkg0s83h54uAp8zsP2Z2F9Armp1LOkPSEknLJX1rTGlJt0paKGmupA8kdQvnd5M0MxyGdIGk66t7YrUlKyONHx7fg1dn5TF95eaqN3DOuUai0gQhqbTQ/RTgw4hlVRbGS0oEHgVGAP2AiyX1K7PaLCDHzAYCLwP3h/PXAUeb2WDgSOB2SZ2rOmas3HBiLzq1SuXu1xdQXNIkWvg651ylCeJ5YJKk14A9wGQASb0IipmqMgxYbma5ZrYPeAEYFbmCmU00s9LC/SlAdjh/n5kVhPObVRFnzDVvlsQdZ/Zhft52Xpq+Op6hOOdcnanwi9fMfgfcBowFhtv/+rxOAG6KYt9ZQOS36ZpwXkWuAd4unZDURdLccB/3mdnashtIulbSdEnT8/Pzowip5kYO6syw7pmMmbCEbbsLY3os55yrDyprxZQJLAUmAc0kZYbzNgIrazMISZcCOcCY0nlmtjoseuoFXCGpY9ntzOwpM8sxs5z27WPb+4ckfj2yH1t37+Mv7y+N6bGcc64+qKwuYSPBr/7SwRAUscyAnlXsOw/oEjGdHc7bj6RTgTuBEyKKlf53ILO1kuYDxxHUU8RN/86t+f6RXXluyleMHtaFPp1axTMc55yLqcrK9h8GtgDvAFcAPc2sR/iqKjkATAN6S+ohKQUYDYyPXCHsvuNJYKSZbYiYny0pLfzcBhgOLKnGecXMbacdSotmSfxm/EIfac4516hVVgfxE2AwMA64DJgl6X5JPaLZsZkVATcCE4BFwEtmtkDSPZJGhquNAVoA48ImraUJpC/whaQ5BEVcfzKzeTU4v1rXpnkKPzv9ED7P3cTb85tMjyPOuSZI0fwKlpRBcAfwW+AXZvZ0rAOrrpycHJs+fXqdHKu4xDj7r5+wfU8h7996AmkpiXVyXOecq22SZphZTnnLKqukbi7p+2Ez17cIfukfUR+TQ11LTBB3n9OPvK17eHzSiniH45xzMVFZJfUGYBnB8wvLCCqmcyTlAJjZK7EPr/46smdbzhnUmScmreCCI7Lpkpke75Ccc65WVVZJPY7gSedDgbOBcyJeZ8c+tPrvjhF9SJS4982F8Q7FOedqXWXdfV9Zh3E0SJ0z0rjx5F6MmbCE12bnMWpwZc8BOudcwxLXLiwag+uO78nhXTP45avzWb3ZuwR3zjUeniAOUFJiAg+NHgLALS/Moqi4JM4ROedc7fAEUQu6ZKZz73cHMHPVVh7+cHm8w3HOuVpR7QQhKSeeXW/XV6MGZ3He4Vk88uEypn7p40Y45xq+mtxB3AS8KenF2g6mobtn1AC6ZKbzkxdmeY+vzrkGr9oJwsyuMLMhwA9iEE+D1qJZEg+NHsKGHQXc8epc76vJOdegVZkgJB0rqXn4+VJJf5bUzcx2xD68hmdwlwxuPf0Q3pq3nnHT18Q7HOecq7Fo7iAeB3ZLGkQwgNAK4J8xjaqBu+74gzm6Z1t+PX4BK/J3xjsc55yrkWgSRFE4mtwo4BEzexRoGduwGrbEBPGXiwbTLDmBm5+fRUFRcbxDcs65aosmQeyQdAdwKUHldAKQHNuwGr5OrVO57/yBLFi7nT+/6yPQOecanmgSxEVAAXCNma0nGBluTOWbOIDv9O/EhTnZPPPJl6za5E9ZO+calqjuIICHzGyypEMIBhF6PrZhNR63nnYoCQni4Q+XxTsU55yrlmgSxMdAM0lZwLsEo8uNjWVQjUmn1qlcemQ3Xpm5hlyvsHbONSDRJAiZ2W7gPOAxM7sAGBDNziWdIWmJpOWSbi9n+a2SFkqaK+kDSd3C+YMlfS5pQbjsouqcVH3zoxMPpllSIg++73cRzrmGI6oEIelo4BLgzWi3k5QIPAqMAPoBF0vqV2a1WUCOmQ0EXgbuD+fvBi43s/7AGcCD4bCnDVL7ls244pjuvD53LUvW++MjzrmGIZoE8RPgDuBVM1sgqScwMYrthgHLzSzXzPYRjEw3KnIFM5sY3p0ATCGoAMfMlprZsvDzWoLR7dpHc0L11XXH96R5ShIPvu8tmpxzDUOVCcLMJpnZSOBRSS3CL/ybo9h3FrA6YnpNOK8i1wBvl50paRiQQvCAXtll10qaLml6fn5+FCHFT5vmKVx9bHfenr+e+Xnb4h2Oc85VKZqiosMkzQIWAAslzZDUvzaDkHQpkEOZ5rOSDgKeA64ys28NtGBmT5lZjpnltG9f/28wrjmuJ61Sk/jLe34X4Zyr/6IpYnoSuNXMuplZV4LuNp6OYrs8oEvEdHY4bz+STgXuBEaaWUHE/FYEdR53mtmUKI5X77VOS+ba43vyweINzFq1Jd7hOOdcpaJJEM3N7Js6BzP7CGgexXbTgN6SekhKAUYD4yNXkDSEIAGNNLMNEfNTgFeBf5rZy1Ecq8G48tgetElP5s9+F+Gcq+eiSRC5ku6S1D18/RLIrWojMysCbgQmAIuAl8JK7nskjQxXGwO0AMZJmi2pNIFcCBwPXBnOny1pcHVPrj5q0SyJ6084mMnLNvrAQs65ek1VjVkgqQ3wG2B4OGsycLeZ1asykpycHJs+fXq8w4jKnn3FHHf/RA5u35wXrj0KSfEOyTnXREmaYWY55S2LphXTFjO72cwOD1+31Lfk0NCkpSTy45MO5osvN/PZik3xDsc558qVVNECSa8DFd5ehE1fXQ1dPKwrT32cywPvLuGYg9v6XYRzrt6pMEEAf6qzKJqg1OREbjy5F3e+Op+PluRzUp8O8Q7JOef2U2GCMLNJdRlIU3TBEV14YtIK7ntnMccf0p7EBL+LcM7VH9G0YnIxkpKUwM+/04fF63fw8ozVVW/gnHN1yBNEnJ098CCGdM3gT+8uZVdBUbzDcc65b3iCiDNJ3HV2P/J3FPDkpG91N+Wcc3FTWSU1UGFrpm3AdOBJM9sbi8CaksO7tuGcQZ15anIuFx/ZlYNap8U7JOeci+5JamAnQf9LTwPbCYYhPYTo+mRyUfj5dw6lxGDMhCXxDsU554Ao7iCAY8xsaMT065KmmdlQSQtiFVhT0yUznauP7cETk1Zw5THdGZjdYMdHcs41EtHcQbSQ1LV0IvzcIpzcF5OomqgbTjqYts1TuPfNRVTVBYpzzsVaNAniNuATSRMlfUTQF9PPJDUH/hHL4JqaVqnJ/PS0Q5j65WYmLPg63uE455q4KjvrA5DUDOgTTi6pjxXTDamzvsoUFZcw4qHJFBaX8O5PTyAlyRuaOedi54A66wsdAfQHBgEXSrq8toJz+0tKTOAXZ/Vl5abdPDflq3iH45xrwqIZcvQ5gn6ZhgNDw1e52cbVjhMPac9xvdvx8AfL2Lrbq3mcc/ERzR1EDnCsmd1gZjeFr5tjHVhTJok7z+rLjr2FPPzB8niH45xroqJJEPOBTrEOxO2vT6dWXDS0K//8fCUr8nfGOxznXBMUTYJoByyUNEHS+NJXNDuXdIakJZKWS7q9nOW3Slooaa6kDyR1i1j2jqStkt6I/nQal1tPO4T0lESuf24G2/YUxjsc51wTE02CuBs4F/g98EDEq1KSEoFHgRFAP+BiSf3KrDYLyDGzgcDLwP0Ry8YAl0URX6PVvmUznrj0CFZu2sWP/jWDfUUl8Q7JOdeERDPk6KTyXlHsexiw3MxyzWwf8AIwqsy+J5rZ7nByCpAdsewDgi49mrRjerXjj+cN5LMVm7jjlXn+AJ1zrs5UmCAkfRK+75C0PeK1Q9L2KPadBUQOcrAmnFeRa4C3owk6IsZrJU2XND0/P786mzYo5x+RzU9O7c1/Zq7xSmvnXJ2pbES54eF7y1gHIelSgtZSJ1RnOzN7CngKggflYhBavXHLKb1ZtXk3f3l/Kdlt0jj/iOyqN3LOuQMQTWd9pfUJHSPXN7NVVWyWB3SJmM4O55Xd96nAncAJZlYQTTxNkST+eN5A1m/by+2vzOWgjFSOObhdvMNyzjVi0TwodxPwNfAe8Gb4iqZl0TSgt6QeklKA0cB+rZ8kDQGeBEaa2YZqxt7kpCQl8PilR9C9bXOue24Gy75u8lU0zrkYiqYV0y3AoWbW38wOC18Dq9rIzIqAG4EJwCLgJTNbIOkeSSPD1cYQ9Aw7TtLsyOazkiYD44BTJK2R9J1qnluj1DotmWevGkpqciJXPjuNDTvqXbdYzrlGosrO+iRNBE4Lv/DrrcbSWV+05q7ZykVPTqF3xxa8eO3RpKUkxjsk51wDdKCd9eUCH0m6I3yw7VZJt9ZuiK66BmZn8NDowcxds42nPs6NdzjOuUYomgSxiqD+IQVoGfFycXZ6/06MGNCJJyat4OvtXtTknKtdVbZiMrPf1EUgrmZuH9GH9xd9zQPvLuH+7w2KdzjOuUaksgflHgzfX4/sg6k6fTG52OvWtjlXHN2dcTPWsGDttniH45xrRCq7g3gufP9TXQTiau6mk3vz8sw1/O7NRfz7B0ciKd4hOecagcqepJ4RvkfT75KLo9bpyfzklN7c/fpCPly8gVP6dox3SM65RiCaB+V6S3o57JY7t/RVF8G56F1yVDd6tmvO795aRGGx9/rqnDtw0bRiehZ4HCgCTgL+CfwrlkG56ktOTOCOM/uSm7+L56dW1QuKc85VLZoEkRZ2vS0z+8rM7gbOim1YriZO7duBo3u25S/vLfUBhpxzByyaBFEgKQFYJulGSd8l6B7D1TOlY1lv3VPIoxO9W3Dn3IGJti+mdOBm4AjgUuCKWAblam5AVmvOPzybsZ+uZNWm3VVv4JxzFag0QYTdfF9kZjvNbI2ZXWVm55vZlDqKz9XAz04/lMQEcd87i+MdinOuAavsQbkkMysGhtdhPK4WdGqdyrXH9+TNeeuY8dXmeIfjnGugKruDmBq+zwqfnr5M0nmlr7oIztXcdSf0pEPLZvzm9YXs2Vcc73Cccw1QNHUQqcAm4GTgbOCc8N3VY+kpSdx1dj/m5W3ju499ysqNu+IdknOugaksQXQIu/WeD8wL3xeE7/PrIDZ3gM4Z1JlnrxzK+u17Oeevn/DugvXxDsk514BUliASCZqztiDo3rtFmZdrAE48tAOv3zic7u2ac+1zM7jvncUU+ZPWzrkoVNZZ3zozu+dAdi7pDOAhgmTzNzP7Y5nltwI/IHhKOx+42sy+CpddAfwyXPVeM/vHgcTSlHXJTGfc9Ufzm9cX8vhHK5izeisPXzyEdi2axTs051w9VtkdxAF1CRo2kX0UGAH0Ay6W1K/MarOAnHCM65eB+8NtM4FfA0cCw4BfS2pzIPE0danJifzhvMMY872BzPhqC2c//AkzvtoS77Ccc/VYZQnilAPc9zBguZnlmtk+4AVgVOQKZjbRzEqf5poCZIefvwO8Z2abzWwLwYh2ZxxgPA64IKcLr9xwDClJCVz05Of8bXKuFzk558pVYYIwswNtQJ8FrI6YXhPOq8g1wNvV2VbStZKmS5qen59/gOE2Hf07t+b1m4Zz4qEduPfNRZz58GQmL/Pr55zbXzTNXGNO0qVADjCmOtuZ2VNmlmNmOe3bt49NcI1U67Rknr78CJ687Aj2FpZw2TNT+cE/pvGlN4d1zoVimSDygC4R09nhvP1IOhW4ExhpZgXV2dYdGEl8p38n3rv1eG4f0YcpuZs5/S+T+N2bC9m+13uDda6pk5nFZsdSErCUoC4jD5gGfN/MFkSsM4SgcvoMM1sWMT8TmAEcHs6aCRxRWbFXTk6OTZ8+vdbPoynZsGMvD0xYykszVpOZnsJtpx/KRUO7kJjgQ5g611hJmmFmOeUti9kdhJkVATcCE4BFwEtmtkDSPZJGhquNIXimYpyk2ZLGh9tuBn5LkFSmAffUQp2Iq0KHlqnc972BvH7jcHq2b84vXp3HBU98xpot3iusc01RzO4g6prfQdQuM+O12Wu567/zkWDMBYP4Tv9O8Q7LOVfL4nIH4Ro2SZw7JIs3bz6O7u2ac91zM7h7/AIKirzjP+eaCk8QrlJd26bz8vXHcM3wHoz9bCXnPcZng88AABdLSURBVPaZt3RyronwBOGqlJKUwF1n9+Nvl+eQt3UPZz88mddme6My5xo7TxAuaqf268hbNx9Hv86tuOWF2fz85Tk+1oRzjZgnCFctnTPSeP6HR3HTyb0YN2MN1/xjGnsLPUk41xh5gnDVlpSYwG2nH8qfLxzE57mbuP5fM7zy2rlGyBOEq7HvDsnm9989jI+W5HPz87O80z/nGhlPEO6AXDysK78+px8TFnzNbePmUFzSOJ6rcc5VPmCQc1G56tge7Cks5v53lpCaFIw7keDdczjX4HmCcLXihhN7sXdfMQ9/uJzU5ATuHtkfyZOEcw2ZJwhXa3562iHsKSzm6clfkpqcyO0j+niScK4B8wThao0kfnFmX/YUFvPkx7mkpSTyk1MPiXdYzrka8gThapUk7hk5gL2FJTz4/jL2Fpbw8+8c6nUSzjVAniBcrUtIEPedP5BmSQk8MWkF67bt4f7vDaRZUmK8Q3POVYMnCBcTiQni3nMH0DkjjTETlrBhewFPXHYErdOS4x2acy5K/hyEixlJ/PikXvz5wkFMW7mZC5/4nLVb98Q7LOdclDxBuJg77/Bsxl41jLytezjvsc9YvH57vENyzkUhpglC0hmSlkhaLun2cpYfL2mmpCJJ3yuz7D5J88PXRbGM08Xe8N7teOm6ozGMCx7/nM+Wb4x3SM65KsSsDkJSIvAocBqwBpgmabyZLYxYbRVwJfCzMtueBRwODAaaAR9JetvM/KdnA9avcyteveFYrnx2Klc8O5XbR/SlfctmbNtTyLbd+9i2p5CtuwuD9z2FdGmTzi/P6kub5inxDt25JimWldTDgOVmlgsg6QVgFPBNgjCzleGysr289QM+NrMioEjSXOAM4KUYxuvqQOeMNMZdfwzXPTed376xcL9lacmJtE5LJiM9mVapyYyfk8enyzfy0OjBHNmzbZwidq7pimWCyAJWR0yvAY6Mcts5wK8lPQCkAycRkVhKSboWuBaga9euBxSsqzut05J57pojWbRuO+kpibRKS6Z1WvK3msHOW7ONm56fycVPT+HmU3pz08m9SfTnKZyrM/WyktrM3gXeAj4Dngc+B7414ICZPWVmOWaW0759+zqO0h2I5MQEBmZn0KtDSzq0TC33GYnDslvzxs3Hce7gLB58fxnff3oK67Z5Kyjn6kosE0Qe0CViOjucFxUz+52ZDTaz0wABS2s5PtcAtGiWxJ8vGswDFwxiXt42znxoMh8s+jreYTnXJMSyiGka0FtSD4LEMBr4fjQbhhXcGWa2SdJAYCDwbswidfXe+UdkM6RrBjc9P4tr/jGdq47tzo9P6gVASYlRbEaJhZ9LjASJLplp3lmgcwdAZrEb4EXSmcCDQCLwdzP7naR7gOlmNl7SUOBVoA2wF1hvZv0lpQIzw91sB643s9mVHSsnJ8emT58es3Nx9UNBUTF/fHsxz366ssp1T+/Xkb9+f4h38eFcJSTNMLOccpfFMkHUJU8QTcuU3E0sWb+DBAV9PyVIJEpIQTcfX27cxV8/XM5xvdvx1GU5pKV4knCuPJUlCO+LyTVIR/Vsy1FVNH3tkpnO7f+ZyxV/n8ozV+bQMtX7gXKuOuplKybnasOFOV14aPQQZq7awqV/+4Ktu/fFOyTnGhRPEK5RO2dQZ5649AgWrd/B6KemkL+jIN4hOddgeIJwjd6p/Try7JVD+WrTbi568sB7lC0oKmZv4bcey3Gu0fEE4ZqEY3u147lrhpG/o4ALnvicrzbtqtb2ZsaMrzZzxyvzyLn3fXLufZ8Xp62isTTycK483orJNSnz1mzj8r9/QVJiAucO7ky/zq3oe1ArDm7fguTEb/9eWrNlN6/OzOOVWXl8uXEXqckJjBhwEOu27WFK7mZO6dOBP5x3GB1apcbhbJw7cN7M1bkIS7/ewR2vzGNe3jb2FQX9RKYkJtC7Ywv6HdSKfp1bkZqcyGuz85iSuxmAI3tkcv4R2Zx52EG0aJZESYkx9rOV3PfOYtJSErn33AGcPbBzPE+rwduwfS8IOrT0ZFuXPEE4V46i4hJyN+5i4drtLFq3nYXrtrNw7XY27QpaO3Vrm855Q7I57/AsumSml7uPFfk7ufWlOcxZvZWzBx7Eb0cNiFv35EEx2BbydxRwSt+OpCQ1nBLkz1Zs5PrnZlBi8Ntz+/PdIdnxDqnJ8AThXJTMjPwdBWzevY9DO7aMqquOouISnpi0goc+WEZGegr3nX8YJ/fpWK3jFpcYs1dv5aMlG5i9eis53TI5d0hnurVtXuW2hcUlvD1/Pc9MzmXOmm0AdG6dyg+P78nooV3r/UOC46av5o5X5tGjXXMy0pOZtnILowZ35rfnDqCVP7sSc54gnKsDC9Zu47aX5rB4/Q6Gdm9Dn06t6N2xBb07tKR3xxa0a9Fsv/U37Szg42X5TFycz8fL8tm6u5AEQc/2LViRvxMzOLxrBt8dksVZAzuTWebOZNueQl6ctoqxn65k7ba99GjXnKuH96Bz61SenJTL1JWbads8hauH9+DSo7rROq1+fdmWlBgPvLeERyeu4Lje7Xj0ksNpnpLEYxOX8+AHyziodSoPXjSYnO6Z8Q61UfME4VwdKSgq5omPcpm0dAPLvt7JjoKib5ZlNk+hV4cW9GzXnMXrdzBnzVbMoF2LFE44pAMn9WnPcb3a0zo9mbVb9zB+zlpenZnHkq93kJQgTjikPecOyaLvQS359xereGnaanbtK+aonpn8YHhPTu7TgYSI8TKmfrmZxz5azkdL8mnZLIlLj+7G1cf2oH3LZuWFXqf2FhZz27g5vDl3HRcP68o9o/rv10hg5qot3PLCLPK27OGmk3tz08m9SCqnEYE7cJ4gnIsDM+Pr7QUs27CDZV/v/OY9d+Muumamc9KhQVIY0Ln1fl/sZS1at53/zsrjv7Pz+Hp78KBfUoI4Z1BnrhnegwFZrSuNY37eNh6ftIK35q0jJTGBy47qxi2n9o5b1yMbdxbww39OZ/bqrdwxog8/PK5nuUV5O/YW8uvXFvDKrDyO6NaGBy8aXGFdUFVWbdrNOwvWcfnR3UlNrt9FbnXNE4RzjUBxifFF7iYWrd/BWYcdRKfW1Wvtk5u/k8c+WsF/Zq6hfYtm3HlWX0YO6lynXaIv37CDq8ZOI39HAQ9eNJgzBhxU5Tavzc7jl6/OB+DOs/pyYU6XShNqJDPjlZl5/Oq1+ezaV8yxvdryt8uH1vt6mbrkCcI5943Zq7dy13/nMy9vG0f3bMs9o/rTu2PLA9pnUXEJ4+es5a156wEjMUEkJSSE7yIpUSQmiDfmrqNZUiLPXJHDoC4ZUe9/9ebd3DZuDlO/3MyQrhn8dtSAKu+ctu0p5M5X5/HG3HUM657J6f078ru3FnFUj7Y8c2UO6SneVyl4gnDOlVFcYjw/dRVjJixhV0ER1wzvwc2n9KZ5s+p9aRYVl/Df2Wt55MNlrNy0my6ZabRKTaa4xCgsLqG4xCgKB3EqKjG6Zabz4OjBZLepflFR6d3AH95exOZd+7jsqG7cevqh5Va+T/1yMz99cTbrt+/lp6f25kcn9iIxQfx3Vh63vjSbod0z+fuVQ6t9vo2RJwjnXLk27SzgvncW89L0NXRqlcpdZ/fjzMM6VVnsVFRcwquz8nhk4nK+2rSbfge14pZTe3Na345RF//U1LY9hfz53SU8N+UrMpuncMeIvpx3eBaSKCwu4eEPlvHoxOVkt0nnodGDGdK1zX7bvzY7j5++OJucbpn8/aqhtKhhktiwfS+frdjEp8s3MnXlZtq1aMZxvdtxXO/2DMpu3WAq1T1BOOcqNeOrLdz13/ksXLedlqlJ9GzfgoPbN+fgiPeubdNJkHh1ZpAYVm3eTf/OrbjllN6c1q9jnQ/vOj9vG3e9Np9Zq7YytHsbbjixFw99sIzZq7dy/uHZ/GZU/wq//N+Yu5ZbXpjNkC4ZPHvV0Kgq7LftLuTz3E18tmIjn63YxPINOwFonZbMsB6ZbNhRwNywZVqr1CSO7RUki+N6t6tx5XpdiFuCkHQG8BDBkKN/M7M/lll+PMGQpAOB0Wb2csSy+4GzCDoUfA+4xSoJ1hOEcwemqLiE12avZfbqrazI30lu/i7Wb9/7zfIEQYtmSWzfW8RhWa255ZTenNK3Q1zH/S4pMcbNWM0f317Mlt2FtExN4vffPYxzBlXd7clb89Zx8/OzGJjdmrFXD/vWQ3l7C4uZ8dUWPlm+kU+Xb2Re3jbMIC05kWE9Mjnm4LYc26sdfQ9qRWJ417Rl1z4+W7GJycvy+XhpPmu3BdevR7vm4SBXmRzZo221GxhAUMS2p7CYbXsKg9fuwm8+t0xNiqrCvzxxSRCSEoGlwGnAGmAacLGZLYxYpzvQCvgZML40QUg6BhgDHB+u+glwh5l9VNHxPEE4V/t2FhSRGyaLFfk7WbdtL2ce1omTDo1vYihr6+59vDxjDWcM6FSt+o135q/nxv+byYCs1oy9aiirNu/+JiFMW7mFfUUlJCWIw7u24ZheQUIYlJ0RVTcmZkbuxl1MXprP5GUbmfrl5m+ei+neNp0je7TlqIODhNE5I419RSWs3bqHVZt3s2rzblZv2c3q8PP6bQVs27OPwuLyv68HZrdm/I3Doz7vSPFKEEcDd5vZd8LpOwDM7A/lrDsWeCMiQRwNPAIMBwR8DFxmZosqOp4nCOdcTby7YD0//r+ZlFhQeQ/Qp1NLju3VjuG92jGsR2atVGYXlxiL1m1nSu4mpuRuZuqXm9i+N0gYbdKT2bankJKIr+OUxASyM9Po0iadzhmptE5LoXVacrmvjObJNe6WJF5jUmcBqyOm1wBHRrOhmX0uaSKwjiBBPFJecpB0LXAtQNeuXQ84YOdc03N6/06MvWoY7y5Yz+Hd2nDMwe1i8rR5YoIYkNWaAVmt+cFxPSkuMRav384XuZtZ+vUOOrRKpWtmOl0z0+mSmUbHlqkxr/CvSr1s4yWpF9AXKO3S8T1Jx5nZ5Mj1zOwp4CkI7iDqNkrnXGNxbK92HNurXZ0eMzFB9O/cmv6dK3+eI55i2Q4rD+gSMZ0dzovGd4EpZrbTzHYCbwNH13J8zjnnKhHLBDEN6C2ph6QUYDQwPsptVwEnSEqSlAycAFRY/+Ccc672xSxBmFkRcCMwgeDL/SUzWyDpHkkjASQNlbQGuAB4UtKCcPOXgRXAPGAOMMfMXo9VrM45577NH5RzzrkmrLJWTA3jWXDnnHN1zhOEc865cnmCcM45Vy5PEM4558rVaCqpJeUDXx3ALtoBG2spnNrmsdWMx1YzHlvNNNTYuplZ+/IWNJoEcaAkTa+oJj/ePLaa8dhqxmOrmcYYmxcxOeecK5cnCOecc+XyBPE/T8U7gEp4bDXjsdWMx1YzjS42r4NwzjlXLr+DcM45Vy5PEM4558rV5BOEpDMkLZG0XNLt8Y4nkqSVkuZJmi0p7j0RSvq7pA2S5kfMy5T0nqRl4XubehLX3ZLywms3W9KZdR1XGEcXSRMlLZS0QNIt4fz6cN0qii3u105SqqSpkuaEsf0mnN9D0hfh/9cXw6EE6ktsYyV9GXHdBtd1bBExJkqaJemNcLpm183MmuwLSCToVrwnkELQtXi/eMcVEd9KoF2844iI53jgcGB+xLz7gdvDz7cD99WTuO4GflYPrtlBwOHh55bAUqBfPbluFcUW92tHMNRwi/BzMvAFcBTwEjA6nP8E8KN6FNtY4Hvx/jcXxnUr8H/AG+F0ja5bU7+DGAYsN7NcM9sHvACMinNM9ZaZfQxsLjN7FPCP8PM/gHPrNCgqjKteMLN1ZjYz/LyDYGyULOrHdasotrizwM5wMjl8GXAywXgxEL/rVlFs9YKkbOAs4G/htKjhdWvqCSILWB0xvYZ68h8kZMC7kmZIujbewVSgo5mtCz+vBzrGM5gybpQ0NyyCqvMinLIkdQeGEPzirFfXrUxsUA+uXVhMMhvYALxHcLe/1YLByCCO/1/LxmZmpdftd+F1+4ukZvGIDXgQ+DlQEk63pYbXrakniPpuuJkdDowAfizp+HgHVBkL7l/ryy+px4GDgcHAOuCBeAYjqQXwH+AnZrY9clm8r1s5sdWLa2dmxWY2mGA8+2FAn3jEUZ6ysUkaANxBEONQIBP4f3Udl6SzgQ1mNqM29tfUE0Qe0CViOjucVy+YWV74vgF4leA/SX3ztaSDAML3DXGOBwAz+zr8T1wCPE0cr104rvp/gH+b2Svh7Hpx3cqLrT5duzCercBE4GggQ1JSuCju/18jYjsjLLIzMysAniU+1+1YYKSklQRF5icDD1HD69bUE8Q0oHdYw58CjAbGxzkmACQ1l9Sy9DNwOjC/8q3iYjxwRfj5CuC1OMbyjdIv39B3idO1C8t/nwEWmdmfIxbF/bpVFFt9uHaS2kvKCD+nAacR1JFMBL4Xrhav61ZebIsjEr4Iyvjr/LqZ2R1mlm1m3Qm+zz40s0uo6XWLd217vF/AmQStN1YAd8Y7noi4ehK0qpoDLKgPsQHPExQ5FBKUY15DUL75AbAMeB/IrCdxPQfMA+YSfBkfFKdrNpyg+GguMDt8nVlPrltFscX92gEDgVlhDPOBX4XzewJTgeXAOKBZPYrtw/C6zQf+RdjSKV4v4ET+14qpRtfNu9pwzjlXrqZexOScc64CniCcc86VyxOEc865cnmCcM45Vy5PEM4558rlCcI1OJJM0gMR0z+TdHct7XuspO9VveYBH+cCSYskTYz1scoc90pJj9TlMV3D5QnCNUQFwHmS2sU7kEgRT6pG4xrgh2Z2Uqzice5AeYJwDVERwRi7Py27oOwdgKSd4fuJkiZJek1SrqQ/Srok7Nd/nqSDI3ZzqqTpkpaGfduUds42RtK0sDO26yL2O1nSeGBhOfFcHO5/vqT7wnm/InhI7RlJY8rZ5v+LOE7pWAPdJS2W9O/wzuNlSenhslPCvv/nhZ3rNQvnD5X0mYJxC6aWPpkPdJb0joKxKO6POL+xYZzzJH3r2rqmpzq/eJyrTx4F5pZ+wUVpENCXoGvwXOBvZjZMwUA5NwE/CdfrTtCPzsHAREm9gMuBbWY2NPwC/lTSu+H6hwMDzOzLyINJ6gzcBxwBbCHomfdcM7tH0skEYy5ML7PN6UDv8PgCxoedNK4CDgWuMbNPJf0duCEsLhoLnGJmSyX9E/iRpMeAF4GLzGyapFbAnvAwgwl6bi0Alkj6K9AByDKzAWEcGdW4rq6R8jsI1yBZ0OvoP4Gbq7HZNAs6VCsg6Fql9At+HkFSKPWSmZWY2TKCRNKHoC+sy8Munr8g6Cqjd7j+1LLJITQU+MjM8i3oavnfBIMbVeb08DULmBkeu/Q4q83s0/DzvwjuQg4FvjSzpeH8f4THOBRYZ2bTILhe9r/unj8ws21mtpfgrqdbeJ49Jf1V0hnAfj3OuqbJ7yBcQ/YgwZfosxHzigh/+EhKIBgpsFRBxOeSiOkS9v+/ULb/GSP4NX+TmU2IXCDpRGBXzcIvl4A/mNmTZY7TvYK4aiLyOhQDSWa2RdIg4DvA9cCFwNU13L9rJPwOwjVYZraZYCjFayJmryQo0gEYSTDaV3VdICkhrJfoCSwBJhAU3SQDSDok7GW3MlOBEyS1k5QIXAxMqmKbCcDVCsZoQFKWpA7hsq6Sjg4/fx/4JIyte1gMBnBZeIwlwEGShob7aVlZJXpY4Z9gZv8BfklQbOaaOL+DcA3dA8CNEdNPA69JmgO8Q81+3a8i+HJvBVxvZnsl/Y2gGGpm2J1zPlUM22hm6yTdTtDVsoA3zazSbpbN7F1JfYHPg8OwE7iU4Jf+EoKBo/5OUDT0eBjbVcC4MAFMA54ws32SLgL+GnZJvQc4tZJDZwHPhnddEAx+45o4783VuQYgLGJ6o7QS2bm64EVMzjnnyuV3EM4558rldxDOOefK5QnCOedcuTxBOOecK5cnCOecc+XyBOGcc65c/z8Xu6QKBTrv+AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}